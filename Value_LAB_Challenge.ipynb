{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Value_LAB_Challenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdYcd5giZ2IF",
        "colab_type": "text"
      },
      "source": [
        "### Getting the Dataset and Pre-Requisite files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1m-l4UACnQ4",
        "colab_type": "code",
        "outputId": "88df3ce8-7708-405f-c505-d6c8c977443a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!unzip 92a4172ee04e11e9.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  92a4172ee04e11e9.zip\n",
            "   creating: DataSet/\n",
            "  inflating: DataSet/Results.csv     \n",
            "  inflating: DataSet/Train.csv       \n",
            "  inflating: DataSet/readme.md       \n",
            "  inflating: DataSet/Sample_Submission.csv  \n",
            "  inflating: DataSet/Test.csv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbxbbcaaDfo2",
        "colab_type": "code",
        "outputId": "a1df3275-f9df-4a49-eee6-c1adc0e79d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "! kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 6, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XonU9JlfD2oY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp kaggle.json /root/.kaggle/kaggle.json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVoxU83dD2r7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DawN9lpSDflZ",
        "colab_type": "code",
        "outputId": "bc8baf69-c2c0-481d-c08f-6fcddaacc842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!kaggle datasets download -d watts2/glove6b50dtxt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove6b50dtxt.zip to /content\n",
            " 93% 63.0M/67.7M [00:01<00:00, 24.7MB/s]\n",
            "100% 67.7M/67.7M [00:01<00:00, 43.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At702lkeD2vv",
        "colab_type": "code",
        "outputId": "82281df2-2a46-42e7-afaa-f65608d010e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip glove6b50dtxt.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove6b50dtxt.zip\n",
            "  inflating: glove.6B.50d.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Ck2Q3iaCYH",
        "colab_type": "text"
      },
      "source": [
        "### Importing the necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "augvOir2Cvz7",
        "colab_type": "code",
        "outputId": "29592b8d-0ab8-401c-b263-bf013fdbf923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential,Model\n",
        "import re\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l09R3IybaIy-",
        "colab_type": "text"
      },
      "source": [
        "### Looking at the Train and Test files to study"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9-I03C5Cv4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"DataSet/Train.csv\")\n",
        "test = pd.read_csv(\"DataSet/Test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWLisqVjCv7k",
        "colab_type": "code",
        "outputId": "38b9d25e-9618-48f4-9ea6-76a4b83bbc3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>distractor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Meals can be served</td>\n",
              "      <td>in rooms at 9:00 p. m.</td>\n",
              "      <td>'outside the room at 3:00 p. m.', 'in the dini...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It can be inferred from the passage that</td>\n",
              "      <td>The local government can deal with the problem...</td>\n",
              "      <td>'If some tragedies occur again ', ' relevant d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The author called Tommy 's parents in order to</td>\n",
              "      <td>help them realize their influence on Tommy</td>\n",
              "      <td>'blame Tommy for his failing grades', 'blame T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It can be inferred from the passage that</td>\n",
              "      <td>the writer is not very willing to use idioms</td>\n",
              "      <td>'idioms are the most important part in a langu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can we deal with snake wounds according to...</td>\n",
              "      <td>Stay calm and do n't move .</td>\n",
              "      <td>'Cut the wound and suck the poison out .'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  ...                                         distractor\n",
              "0                                Meals can be served  ...  'outside the room at 3:00 p. m.', 'in the dini...\n",
              "1           It can be inferred from the passage that  ...  'If some tragedies occur again ', ' relevant d...\n",
              "2     The author called Tommy 's parents in order to  ...  'blame Tommy for his failing grades', 'blame T...\n",
              "3           It can be inferred from the passage that  ...  'idioms are the most important part in a langu...\n",
              "4  How can we deal with snake wounds according to...  ...          'Cut the wound and suck the poison out .'\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gsa4BNACwAD",
        "colab_type": "code",
        "outputId": "d9086dbc-f865-4975-c870-c3412427437d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What 'S the main idea of the text ?</td>\n",
              "      <td>The lack of career -- based courses in US high...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the summer high season , Finland does nt se...</td>\n",
              "      <td>the sun is out at night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If you want to apply for Chinese Business Inte...</td>\n",
              "      <td>have to get confirmed at least twice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That afternoon , the boy 's clothes were dry b...</td>\n",
              "      <td>nobody made room for him in the water .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which of the following statements is NOT true ?</td>\n",
              "      <td>There are twelve countries in the World Wildli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question                                        answer_text\n",
              "0                What 'S the main idea of the text ?  The lack of career -- based courses in US high...\n",
              "1  In the summer high season , Finland does nt se...                            the sun is out at night\n",
              "2  If you want to apply for Chinese Business Inte...               have to get confirmed at least twice\n",
              "3  That afternoon , the boy 's clothes were dry b...            nobody made room for him in the water .\n",
              "4    Which of the following statements is NOT true ?  There are twelve countries in the World Wildli..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIAVBF9THYEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.values\n",
        "test = test.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcRXG72zKZ24",
        "colab_type": "code",
        "outputId": "db15a541-fb2a-42fc-b119-2b4c6dc32a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31499"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8qHV2fyaUKw",
        "colab_type": "text"
      },
      "source": [
        "### Forming the dictionary for Question as key and Answer and Distractors as items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k91lvT7iCwEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers = {}\n",
        "distractors = {}\n",
        "count = 0\n",
        "for x in range(train.shape[0]):\n",
        "  answers[train[x][0]] = train[x][1]\n",
        "  a=[]\n",
        "  for y in train[x][2].split(\", \"):\n",
        "    a.append(str(y[1:-1]))\n",
        "  distractors[train[x][0]] = a\n",
        "  count = count+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGbCwQcwCwIO",
        "colab_type": "code",
        "outputId": "60986244-2013-4422-ab79-222bd91950f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31499"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Uv4SguCwMj",
        "colab_type": "code",
        "outputId": "a7fca666-3056-4ae4-876b-16689be7e16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "distractors[\"Meals can be served\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['outside the room at 3:00 p. m.',\n",
              " 'in the dining - room at 6:00 p. m.',\n",
              " 'in the dining - room from 7:30 a. m. to 9:15 p. m.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZl2Pa2rakSh",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning the Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuFoWHvpYHMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(sentence):\n",
        "  sentence = sentence.lower()\n",
        "  sentence = re.sub(\"[^a-z0-9]+\",\" \" , sentence)\n",
        "  sentence = sentence.split()\n",
        "  \n",
        "  sentence = [s for s in sentence if((len(s)>1) or (re.match(\"[0-9]+\",s) is not None))]\n",
        "  sentence = \" \".join(sentence)\n",
        "  \n",
        "  return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJQThFRIYUNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean all the captions\n",
        "a={}\n",
        "d={}\n",
        "for key , dist_list in distractors.items():\n",
        "  for i in range(len(dist_list)):\n",
        "    dist_list[i] = clean_text(dist_list[i])\n",
        "  answer=clean_text(answers[key])\n",
        "  key=clean_text(key)\n",
        "  a[key]=answer\n",
        "  d[key]=dist_list\n",
        "answers=a\n",
        "distractors=d\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uUZ-XWkaiIe",
        "colab_type": "code",
        "outputId": "8f55bfd3-7afa-4ef0-a590-121ae2826d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "distractors[\"meals can be served\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['outside the room at 3 00',\n",
              " 'in the dining room at 6 00',\n",
              " 'in the dining room from 7 30 to 9 15']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrr9cG2caqW_",
        "colab_type": "text"
      },
      "source": [
        "### Saving the Answers and Distractors to text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FF7--dFCwQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"answers.txt\",\"w\") as f:\n",
        "  f.write(str(answers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8YN6EdHCwUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"distractors.txt\",\"w\") as f:\n",
        "  f.write(str(distractors))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXwt6FqFQIT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "for key in answers.keys():\n",
        "  [vocab.update(key.split())]\n",
        "  [vocab.update(answers[key].split())]\n",
        "  [vocab.update(sentence.split()) for sentence in distractors[key]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xM1ebSkSXXe",
        "colab_type": "code",
        "outputId": "c34bbad0-aadb-4aec-8700-c1e988ec50c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRD4CTsUSat6",
        "colab_type": "code",
        "outputId": "17e5d08c-571e-40c8-c922-eb0d900c4d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total = []\n",
        "for key in answers.keys():\n",
        "  [total.append(i) for i in key.split()]\n",
        "  [total.append(i) for i in answers[key].split()]\n",
        "  [total.append(i) for des in distractors[key] for i in des.split()]\n",
        "\n",
        "print(len(total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "718584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdQNVaXqSmiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "counter = collections.Counter(total)\n",
        "freq_cnt = dict(counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWlrUccFVEla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_freq_cnt = sorted(freq_cnt.items(),reverse = True,key = lambda x:x[1])\n",
        "\n",
        "threshold =10\n",
        "sorted_freq_cnt = [x for x in sorted_freq_cnt if x[1]>threshold]\n",
        "total_words = [x[0] for x in sorted_freq_cnt]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOzIT4AdV0Sz",
        "colab_type": "code",
        "outputId": "058efc26-64fa-4c3d-d74b-4019234d08cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sorted_freq_cnt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FBWcZora5pW",
        "colab_type": "text"
      },
      "source": [
        "### Appending unique words for Start and End of sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2b0lwsMV282",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_distractors = {}\n",
        "for key in distractors.keys():\n",
        "  train_distractors[key] = []\n",
        "  for dist in distractors[key]:\n",
        "    dist_to_append = \"StartSeq \" + dist + \" EndSeq\"\n",
        "    train_distractors[key].append(dist_to_append)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH0fx5l8eGet",
        "colab_type": "code",
        "outputId": "558a4ce9-d6d8-44bd-cf41-f8d7e5eff28c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(train_distractors[\"meals can be served\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['StartSeq outside the room at 3 00 EndSeq', 'StartSeq in the dining room at 6 00 EndSeq', 'StartSeq in the dining room from 7 30 to 9 15 EndSeq']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCErV10beUj2",
        "colab_type": "code",
        "outputId": "6b1b3767-e1d4-4d1b-a869-aa0be7cd9a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(total_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4723"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSXMVMuroUXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_idx = {}\n",
        "idx_to_word = {}\n",
        "\n",
        "for i,word in enumerate(total_words):\n",
        "  word_to_idx[word] = i+1\n",
        "  idx_to_word[i+1] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWMtXVKeojNc",
        "colab_type": "code",
        "outputId": "c20a6423-bd4f-4fa2-e4f1-3a135b0a0086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(word_to_idx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4723"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqoVOt9-ojRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_idx[\"StartSeq\"]=4724\n",
        "idx_to_word[4724] = \"StartSeq\"\n",
        "\n",
        "word_to_idx[\"EndSeq\"]=4725\n",
        "idx_to_word[4725] = \"EndSeq\"\n",
        "\n",
        "vocab_size = len(word_to_idx) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl4qITlrojW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size= vocab_size+1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl9Hp37udPa5",
        "colab_type": "code",
        "outputId": "5190b9bc-69b6-44f1-d83a-2edc35d98057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4726"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmR5G_7nojY6",
        "colab_type": "code",
        "outputId": "2e0f61e4-81eb-43f8-ecf2-0e9591449c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len=0\n",
        "for key in train_distractors.keys():\n",
        "  for dist in train_distractors[key]:\n",
        "    max_len = max(max_len,len(dist.split()))\n",
        "print(max_len)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go2KGjV0JmAD",
        "colab_type": "code",
        "outputId": "c4eedf11-3558-4d2f-bfc6-2fe6e79b71b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_q=0\n",
        "for key in train_distractors.keys():\n",
        "  max_q = max(max_q,len(key.split()))\n",
        "print(max_q)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwYOUI-IKKQE",
        "colab_type": "code",
        "outputId": "e9aa19d8-acf6-4333-b79a-999f9348b7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_a = 0\n",
        "for key in answers.keys():\n",
        "  max_a = max(max_a,len(answers[key].split()))\n",
        "print(max_a)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkpFrCAhbHyi",
        "colab_type": "text"
      },
      "source": [
        "### Generating Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuBKBU0Sojeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(train_distractors,answers,word_to_idx,max_len,batch_size):\n",
        "  X1,X2,X3,y = [],[],[],[]\n",
        "  \n",
        "  n=0\n",
        "  while True:\n",
        "    for key,dist_list in train_distractors.items():\n",
        "      n+=1\n",
        "      \n",
        "      question = key\n",
        "      answer = answers[key]\n",
        "      \n",
        "      \n",
        "      seqq = [word_to_idx[wordQ] for wordQ in question.split() if wordQ in word_to_idx]\n",
        "      question= pad_sequences([seqq],maxlen=max_q,value=0,padding='post')[0]\n",
        "      \n",
        "      \n",
        "      seqa = [word_to_idx[wordA] for wordA in answer.split() if wordA in word_to_idx]\n",
        "      answer = pad_sequences([seqa],maxlen=max_a,value=0,padding='post')[0]\n",
        "      \n",
        "      for dist in dist_list:\n",
        "        seq = [word_to_idx[word] for word in dist.split() if word in word_to_idx]\n",
        "        for i in range(1,len(seq)):\n",
        "          xi = seq[0:i]\n",
        "          yi = seq[i]\n",
        "          \n",
        "          xi = pad_sequences([xi],maxlen=max_len,value = 0,padding='post')[0] \n",
        "          yi = to_categorical([yi],num_classes = vocab_size)[0]\n",
        "          \n",
        "          \n",
        "          \n",
        "          X1.append(question)\n",
        "          X2.append(answer)\n",
        "          X3.append(xi)\n",
        "          y.append(yi)\n",
        "        if n==batch_size:\n",
        "          yield[[np.array(X1),np.array(X2),np.array(X3)],np.array(y)]\n",
        "          X1,X2,X3,y = [],[],[],[]\n",
        "          n=0\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CitEnZjpbNna",
        "colab_type": "text"
      },
      "source": [
        "### Importing the Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgFrk3q6ojjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f=open(\"./glove.6B.50d.txt\",encoding=\"utf8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV9YzLyNojnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_index = {}\n",
        "for line in f:\n",
        "  values=line.split()\n",
        "  word = values[0]\n",
        "  embedding_index[word]=np.array(values[1:],dtype='float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZogXCRf3ojst",
        "colab_type": "code",
        "outputId": "e97ae589-2f83-4b6a-f237-c5a5fe4d7c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "embedding_index['apple']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.52042 , -0.8314  ,  0.49961 ,  1.2893  ,  0.1151  ,  0.057521,\n",
              "       -1.3753  , -0.97313 ,  0.18346 ,  0.47672 , -0.15112 ,  0.35532 ,\n",
              "        0.25912 , -0.77857 ,  0.52181 ,  0.47695 , -1.4251  ,  0.858   ,\n",
              "        0.59821 , -1.0903  ,  0.33574 , -0.60891 ,  0.41742 ,  0.21569 ,\n",
              "       -0.07417 , -0.5822  , -0.4502  ,  0.17253 ,  0.16448 , -0.38413 ,\n",
              "        2.3283  , -0.66682 , -0.58181 ,  0.74389 ,  0.095015, -0.47865 ,\n",
              "       -0.84591 ,  0.38704 ,  0.23693 , -1.5523  ,  0.64802 , -0.16521 ,\n",
              "       -1.4719  , -0.16224 ,  0.79857 ,  0.97391 ,  0.40027 , -0.21912 ,\n",
              "       -0.30938 ,  0.26581 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fff1Gu6FCO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getEmbeddingMatrix():\n",
        "  emb_dim=50\n",
        "  matrix = np.zeros((vocab_size,emb_dim))\n",
        "  for word,idx in word_to_idx.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      matrix[idx] = embedding_vector\n",
        "  return matrix    \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY3lOoKBGNFh",
        "colab_type": "code",
        "outputId": "5dc60604-358e-4468-c67a-86e4ff9ac4e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix = getEmbeddingMatrix()\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4726, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAOQYk7qGNJc",
        "colab_type": "code",
        "outputId": "83aa93fc-08c4-4453-f5bc-cb30e994de59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embedding_matrix[4724]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PftdjmFDGNNU",
        "colab_type": "code",
        "outputId": "e01a0584-55fe-473e-bde0-6d22ee86b397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDlptBUHbWE6",
        "colab_type": "text"
      },
      "source": [
        "## Architecture of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQNtAJrUGNQC",
        "colab_type": "code",
        "outputId": "f8592038-e576-4519-f468-52e15dca60f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "input_dist = Input(shape = (max_len,))\n",
        "input_dist1=  Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_dist)\n",
        "input_dist2 = Dropout(0.3)(input_dist1)\n",
        "input_dist3 = LSTM(256)(input_dist2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmCZFgOfGNVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ques = Input(shape = (max_q,))\n",
        "input_ques1=  Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_ques)\n",
        "input_ques2 = Dropout(0.3)(input_ques1)\n",
        "input_ques3 = LSTM(256)(input_ques2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC6YXOlHLxC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ans = Input(shape = (max_a,))\n",
        "input_ans1=  Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_ans)\n",
        "input_ans2 = Dropout(0.3)(input_ans1)\n",
        "input_ans3 = LSTM(256)(input_ans2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1YnwmNgL7ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder1 = add([input_dist3,input_ques3,input_ans3])\n",
        "decoder2 = Dense(512 ,activation = 'relu')(decoder1)\n",
        "outputs = Dense(vocab_size,activation= 'softmax')(decoder2)\n",
        "\n",
        "model = Model(inputs = [input_ques,input_ans,input_dist],outputs = outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhvvWJwINJTE",
        "colab_type": "code",
        "outputId": "5047e5d7-e294-4828-8b1e-ac3e0125270a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 30)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 48)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 101)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 30, 50)       236300      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 48, 50)       236300      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 101, 50)      236300      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 30, 50)       0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 48, 50)       0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 101, 50)      0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 256)          314368      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 256)          314368      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 256)          314368      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256)          0           lstm_1[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          131584      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4726)         2424438     dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,208,026\n",
            "Trainable params: 4,208,026\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00kSJbA2NLY-",
        "colab_type": "code",
        "outputId": "00df076d-2391-4a47-efe4-bbb8646b63d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.layers[3].set_weights([embedding_matrix])\n",
        "model.layers[3].trainable = False  \n",
        "\n",
        "model.layers[4].set_weights([embedding_matrix])\n",
        "model.layers[4].trainable = False  \n",
        "model.layers[5].set_weights([embedding_matrix])\n",
        "model.layers[5].trainable = False  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRj_GLEtN_wN",
        "colab_type": "code",
        "outputId": "79bbbf3b-4b5d-432c-e836-3b7d41fd44f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer = 'adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3FFbS9IUT9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"model_19.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewuSuARCN_z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=20\n",
        "number_of_ques = 64\n",
        "steps = len(train_distractors)//number_of_ques"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR_wUu9oN__i",
        "colab_type": "code",
        "outputId": "8a612bf8-7fa1-405c-dab8-70c2c8d1bf1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir model_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model_weights’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgPvQOVMN_4S",
        "colab_type": "code",
        "outputId": "bdb7231f-8e7b-44bc-fb2f-374af9620001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "for i in range(epochs):\n",
        "  generator = data_generator(train_distractors,answers,word_to_idx,max_len,number_of_ques)\n",
        "  model.fit_generator(generator,epochs=1,steps_per_epoch = steps,verbose = 1)\n",
        "  model.save(\"./model_weights/model_\"+str(i)+\".h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 870ms/step - loss: 5.8591\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 314s 875ms/step - loss: 5.2250\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 318s 886ms/step - loss: 4.8554\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 318s 885ms/step - loss: 4.6086\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 319s 888ms/step - loss: 4.4184\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 319s 889ms/step - loss: 4.2585\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 319s 889ms/step - loss: 4.1172\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 317s 884ms/step - loss: 3.9839\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 869ms/step - loss: 3.8612\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 869ms/step - loss: 3.7444\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 870ms/step - loss: 3.6385\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 870ms/step - loss: 3.5394\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 869ms/step - loss: 3.4503\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 869ms/step - loss: 3.3677\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 869ms/step - loss: 3.2924\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 869ms/step - loss: 3.2243\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 869ms/step - loss: 3.1636\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 870ms/step - loss: 3.1005\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 312s 870ms/step - loss: 3.0534\n",
            "Epoch 1/1\n",
            "359/359 [==============================] - 313s 871ms/step - loss: 3.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttQIvbKnbjom",
        "colab_type": "text"
      },
      "source": [
        "### Pre-processing for Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl94GpOJhpoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers_t = {}\n",
        "count = 0\n",
        "for x in range(test.shape[0]):\n",
        "  answers_t[test[x][0]] = test[x][1]\n",
        "  count = count+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXVhJfx2lkL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a={}\n",
        "for key , answer in answers_t.items():\n",
        "  answer=clean_text(answers_t[key])\n",
        "  key=clean_text(key)\n",
        "  a[key]=answer\n",
        "answers_t=a\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHaiH3yflkIZ",
        "colab_type": "code",
        "outputId": "9892fac8-7352-4300-c948-102798594f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(answers_t[\"what the main idea of the text\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lack of water affects california crops\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GflgjB92VT3N",
        "colab_type": "code",
        "outputId": "9fb8bdc7-b647-4a07-b11b-ffaf74934ac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(answers_t.keys()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzn7rBAPVnX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.read_csv(\"Result.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ajiq0w1Vnd-",
        "colab_type": "code",
        "outputId": "9fd1714e-2c6c-4986-926f-ccffab74ba09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "result.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>distractor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What 'S the main idea of the text ?</td>\n",
              "      <td>The lack of career -- based courses in US high...</td>\n",
              "      <td>'the difference of tests in learning and moder...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the summer high season , Finland does nt se...</td>\n",
              "      <td>the sun is out at night</td>\n",
              "      <td>'the sun is too unclear', 'there is no time to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If you want to apply for Chinese Business Inte...</td>\n",
              "      <td>have to get confirmed at least twice</td>\n",
              "      <td>'have more printed books', 'take to the new yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That afternoon , the boy 's clothes were dry b...</td>\n",
              "      <td>nobody made room for him in the water .</td>\n",
              "      <td>'the monkey could let him', 'he did want to ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which of the following statements is NOT true ?</td>\n",
              "      <td>There are twelve countries in the World Wildli...</td>\n",
              "      <td>'the chinese people do like the harm of the en...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  ...                                         distractor\n",
              "0                What 'S the main idea of the text ?  ...  'the difference of tests in learning and moder...\n",
              "1  In the summer high season , Finland does nt se...  ...  'the sun is too unclear', 'there is no time to...\n",
              "2  If you want to apply for Chinese Business Inte...  ...  'have more printed books', 'take to the new yo...\n",
              "3  That afternoon , the boy 's clothes were dry b...  ...  'the monkey could let him', 'he did want to ta...\n",
              "4    Which of the following statements is NOT true ?  ...  'the chinese people do like the harm of the en...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP63yKVfVnpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = result.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqQbPWJeVnvH",
        "colab_type": "code",
        "outputId": "e3460679-152b-485a-972f-dea96ce3a553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13500, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WmODfm_bsNk",
        "colab_type": "text"
      },
      "source": [
        "### Predicting the Distractors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2O5eVhigesb",
        "colab_type": "code",
        "outputId": "220d4dd2-6d7e-4a0a-d503-7f59a30f5366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(results[9100:9200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['What is a resolution ?' 'Something you say .'\n",
            "  \"'you re', 'it nice', 'how'\"]\n",
            " ['Which of the following is true according to the passage ?'\n",
            "  '\" Fast food fanatics \" usually do not stock their fridges with fresh fruit .'\n",
            "  \"'foods foods are more than than regular', 'the foods drinks color are harmful', 'we can buy shoes instead clothes'\"]\n",
            " ['What did the man do when he saw the writer ?'\n",
            "  'He helped her without hesitation .'\n",
            "  \"'he did want to go his way', 'she was afraid of the little boy', 'bought the hand'\"]\n",
            " ['\" Do remember to put it into the letter box on your way to work \" showed'\n",
            "  \"Mrs. Black doubted her husband 's memory\"\n",
            "  \"'betty sister', 'mary sister', 'the man room'\"]\n",
            " ['Why do many people like visiting museums ?'\n",
            "  'Because visits to museums can help gain knowledge .' nan]\n",
            " ['Compared with the device designed by Larry Rome , this new device'\n",
            "  'produces power without adding more loads to the walker' nan]\n",
            " ['Which way is NOT mentioned   in the passage ?'\n",
            "  'Listen to and sing English songs .' nan]\n",
            " ['According to the passage , Alice Munro was awarded the 2013 Noble Prize in Literature mainly for'\n",
            "  'she is a master of the contemporary short story' nan]\n",
            " ['According to the passage , kmad.org' 'provides some goods sold online'\n",
            "  nan]\n",
            " ['The main purpose of this advertisement is to'\n",
            "  'encourage more people to get registered for the Forum in time' nan]\n",
            " ['Underwater archaeologists are worried because'\n",
            "  'sold artifacts can hardly be regained for research' nan]\n",
            " ['We learn that before coins and paper money were used ,'\n",
            "  'many kinds of things were used for exchanging' nan]\n",
            " ['Compared with other books about the Royal Family , the biggest advantage of The Final Curtsey is that'\n",
            "  'its author knows the Queen well' nan]\n",
            " ['Which of the following can serve as the best title for the passage ?'\n",
            "  'Time to Kick the Habit' nan]\n",
            " ['What should one plan to do if going somewhere in the winter ?'\n",
            "  'Put on several layers of clothing .' nan]\n",
            " ['What is the main reason why people said \" what a shame ! \" ?'\n",
            "  'Bill could have returned home with the gold medal in time .' nan]\n",
            " ['What is the purpose of the passage ?'\n",
            "  'To give some information about Brightman .' nan]\n",
            " ['What advice did girl get from wise people ?'\n",
            "  'To forgive those who hurt her .' nan]\n",
            " ['According to the passage , there was an accident once when people'\n",
            "  'watched crocodiles in the \" Cage of Death \" in Darwin' nan]\n",
            " ['Drinking tea has lots of advantages EXCEPT'\n",
            "  'having a strong wish for food' nan]\n",
            " ['What happened to Mandela when he was about to give the speech ?'\n",
            "  \"He had to use his wife 's glasses .\" nan]\n",
            " [\"According to the passage , the writer 's mother\"\n",
            "  'kept up most of the night in order not to miss the wakeup call .' nan]\n",
            " ['Whose birthday is it ?' \"It 's Sue 's .\" nan]\n",
            " ['Tom cried when Henry read the yellowed letter , because'\n",
            "  \"he felt sad at the thought of Henry 's wife\" nan]\n",
            " [\"If you want to know what 's on in the cinema , you 'd better read\"\n",
            "  'the amusement section' nan]\n",
            " ['What will happen when an Argentinian meets a Scandinavian ?'\n",
            "  'The Argentinian will try to contact the Scandinavian .' nan]\n",
            " ['Which of the following will help to cost you less for a flight ?'\n",
            "  'Book early morning flights .' nan]\n",
            " ['Which of the following statements is true according to the passage ?'\n",
            "  'The fist web browser was very expensive to buy' nan]\n",
            " ['Which of the following Hwys is closest to the Hampton Inn Boone hotel ?'\n",
            "  'Hwy105' nan]\n",
            " ['From the passage , we can infer that a perfectionist will   .'\n",
            "  'pay attention to details more than their major goals' nan]\n",
            " ['The author intends to'\n",
            "  'tell us the family is very important to children' nan]\n",
            " ['The best title of this passage is    '\n",
            "  'Exercising to Music Pumps up Brain Power' nan]\n",
            " ['The ban on all cellphone use by drivers was put forward'\n",
            "  \"after about ten years ' investigation in it\" nan]\n",
            " ['What does the author mean by saying\"the British drought well and truly over \" ?'\n",
            "  \"The British people 's desire for a Wimbledon victory is fully satisfied .\"\n",
            "  nan]\n",
            " ['From the letter , we can learn that the author is'\n",
            "  'a regular customer of the store' nan]\n",
            " [\". This passage does n't tell us if we can\"\n",
            "  'publish / sell the puzzles we create' nan]\n",
            " ['A person needs exercise because' 'it makes him healthy' nan]\n",
            " ['The purpose of the passage is to teach you'\n",
            "  'what to do when a friendship changes' nan]\n",
            " ['If a lady receives an invitation marked with \" formal \" , she should wear'\n",
            "  'a long dress' nan]\n",
            " ['According to the text , the author may disagree with the idea that'\n",
            "  \"the SAT helps measure students ' ability of reasoning through their creativity and imagination\"\n",
            "  nan]\n",
            " ['Which of the following is NOT true ?'\n",
            "  'Some Portuguese settled in Macao and made their homes nearly a century ago .'\n",
            "  nan]\n",
            " ['After John found his father ,' 'he started a rich life' nan]\n",
            " ['The town of Guiya in Guangdong Province'\n",
            "  'has serious e - waste pollution' nan]\n",
            " ['Which of the following is TRUE , according to the passage ?'\n",
            "  'With parent and teachers caring for the child , he may feel supported .'\n",
            "  nan]\n",
            " [\"Susan did n't tell Grandma about Jackie 's secret because\"\n",
            "  'she wanted Jackie to do something for her' nan]\n",
            " ['Which of the following is NOT true ?'\n",
            "  \"Tim 's programs were placed on to the Internet in 1990 .\" nan]\n",
            " [\"What 's the passage mainly about ?\"\n",
            "  \"Playing is good for children 's development .\" nan]\n",
            " ['From what Lenny did , we can conclude that    ' 'Lenny was brave' nan]\n",
            " ['What would be the best title of the text ?    '\n",
            "  'The painting on the wall .' nan]\n",
            " ['What is the main theme of the article ?'\n",
            "  'A comparison between lifestyles of generations .' nan]\n",
            " ['\" Fate of the World \" in the passage refers to'\n",
            "  'a computer game on climate change' nan]\n",
            " ['Which of the following is NOT TRUE ?'\n",
            "  'Jack and Bob go to the zoo at last .' nan]\n",
            " ['What does show rooming mean in the text ?'\n",
            "  'Trying in shops and buying online .' nan]\n",
            " ['What can you do in July , 2011 ?'\n",
            "  'Do some volunteering work locally .' nan]\n",
            " ['Which sentence is true ?' 'Everyone has a good time at the party .'\n",
            "  nan]\n",
            " ['What does \" artificial stupidity \" in Paragragh 3 mean ?'\n",
            "  'AI discourages skilled work .' nan]\n",
            " ['.After their children were born , the writer'\n",
            "  'looked after her children as a professional ( , ) housewife' nan]\n",
            " ['We can learn that the future of crosstalk first lies in'\n",
            "  \"young people 's awareness of its value\" nan]\n",
            " ['The passage is mainly about' 'the ways to protect the environment' nan]\n",
            " ['How did the man get the books ?    ' 'He stole them from the car .'\n",
            "  nan]\n",
            " ['What would be the best title for the passage ?'\n",
            "  'A special pair of new shoes' nan]\n",
            " ['The best title    for this passage    would be'\n",
            "  'What British and American people wear nowadays' nan]\n",
            " ['Which of these sentences about exercising is true ?'\n",
            "  'Exercising good for heart .' nan]\n",
            " ['Which of the follwing would be the best title for the passage ?'\n",
            "  'Homeschool materials in songs' nan]\n",
            " ['What can be the best title for the passage ?' 'Hugging Life' nan]\n",
            " ['Craig Venter and his team are working to'\n",
            "  'produce the first artificial bacteria' nan]\n",
            " ['In the Festival , you can' 'buy copies of ancient advertisements' nan]\n",
            " ['From the news report we know that'\n",
            "  'parents have little idea of how to teach children time' nan]\n",
            " ['Family values can be passed on if' 'parents foster them intentionally'\n",
            "  nan]\n",
            " ['If you want to be a member of Summer Science Class , you should'\n",
            "  'call a phone 8455344517' nan]\n",
            " ['Who can apply for the exchange programme ?'\n",
            "  'Students in English and Drama' nan]\n",
            " ['Which of the following the true about the tour ?'\n",
            "  'It offers chances to take great photos .' nan]\n",
            " ['Lightning Ridge is a place where dreams can be fulfilled because'\n",
            "  'there are precious stones and life is peaceful' nan]\n",
            " [\"Why did n't the Venezuelan police go into the man 's bedroom ?\"\n",
            "  'The Venezuelan police were not allowed to enter Colombia .' nan]\n",
            " [\"According to the passage , the followings are all reasons for Wal - Mart 's sales declined in April except\"\n",
            "  'cheaper goods' nan]\n",
            " ['The popularity of The Lord of the Rings proves'\n",
            "  'the general existence of the sense of curiosity' nan]\n",
            " ['By using mass marketing , Asa tried many ways EXCEPT'\n",
            "  'paying $ 2,300 for the rights to Coca - Cola' nan]\n",
            " ['According to Dr SueHuei Chen , what can we do to prevent game addiction ?'\n",
            "  'Care much for the young and improve their ability to get along with others .'\n",
            "  nan]\n",
            " ['In her article in The Telegraph , we can infer Anne Hidalgo'\n",
            "  'showed an objective attitude toward London and Paris .' nan]\n",
            " ['If we travel by car , we can    ' 'make our own timetable' nan]\n",
            " ['How do the plants on green roofs get watered ?'\n",
            "  'Rainwater is often kept in the green roof system for later use' nan]\n",
            " ['Which of the following statements is NOT true according to the passage ?'\n",
            "  'the neighbour fixed needles on his own head' nan]\n",
            " ['This passage primarily deals with' 'conditions of life in Biosphere 2'\n",
            "  nan]\n",
            " ['According to the high level official , it is easy for teenagers lacking independence and responsibility to'\n",
            "  'suffer from loneliness and anxiety' nan]\n",
            " ['Which of the following statements is TRUE according to the passage ?'\n",
            "  'Johnson believes that Oxygen sensors also exist in human skin .' nan]\n",
            " ['Which of the following is the best title ?' 'I Never Write Right' nan]\n",
            " ['Some animals living in groups are similar to humans in'\n",
            "  'following certain rules' nan]\n",
            " ['Which one is NOT true according to the passage ?'\n",
            "  'Families prefer traditional camps to special camps .' nan]\n",
            " ['What does the passage mainly want to tell us ?'\n",
            "  'Dinner customs in the US restaurants .' nan]\n",
            " ['What does the story seem to tell you ?'\n",
            "  '.Being poor is not necessarily a bad thing .' nan]\n",
            " ['Why did some of the customers admire them ?'\n",
            "  'Because they have been together for many years' nan]\n",
            " ['Which of the following is holiday for family ?' \"St. Patrick 's Day .\"\n",
            "  nan]\n",
            " ['From the study , we know that    '\n",
            "  'some kinds of bacteria live on our skin because of dog ownership .'\n",
            "  nan]\n",
            " ['Compared with online chat , face - to - face communication allows people'\n",
            "  'to better understand what other people are working on' nan]\n",
            " ['She realized burglars had been in the flat when'\n",
            "  'she saw the living room was out of order' nan]\n",
            " ['Which of the following is TRUE about the Hundred Years Starship ?'\n",
            "  'It aims to explore new lands in the universe .' nan]\n",
            " ['What can we infer from the passage ?'\n",
            "  'Both Mike and Zac had adventured spirits .' nan]\n",
            " ['Ten students ride the bikes to school because they live'\n",
            "  'not far from the school' nan]\n",
            " ['Where are their Coffee Republic shops ?' 'All over the UK .' nan]\n",
            " ['What can we learn about the volunteering ?'\n",
            "  'It is easy to find a homeless shelter to volunteer .' nan]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhlAv9r4QNvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_distractors(X1,X2):\n",
        "  dists = []\n",
        "  for j in range(3):\n",
        "    in_text = \"StartSeq\"\n",
        "    for i in range(max_len):\n",
        "      sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx]\n",
        "      sequence = pad_sequences([sequence],maxlen=max_len,padding = 'post')[0]\n",
        "      XQ = []\n",
        "      XA = []\n",
        "      XI = []\n",
        "      XQ.append(X1)\n",
        "      XA.append(X2)\n",
        "      XI.append(sequence)\n",
        "      y_pred = model.predict([np.array(XQ),np.array(XA),np.array(XI)])\n",
        "      \n",
        "      if(i<=1):\n",
        "        y_pred=np.array(y_pred)\n",
        "        y_pred = y_pred.argsort()\n",
        "        y_pred=y_pred[0][:]\n",
        "        y_pred=y_pred[len(y_pred)-1-j]\n",
        "      else:\n",
        "        y_pred=y_pred.argmax()\n",
        "      word = idx_to_word[y_pred]\n",
        "      in_text += (' ' + word)\n",
        "\n",
        "      if word == 'EndSeq':\n",
        "        break\n",
        "    final_dists = in_text.split()[1:-1]\n",
        "    final_dists = ' '.join(final_dists)\n",
        "    dists.append(final_dists)\n",
        "  return dists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haZol5yIhpra",
        "colab_type": "code",
        "outputId": "f4a943b0-687c-4636-e506-0e1830f7121e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "L = []\n",
        "for i in range(9100,results.shape[0]):\n",
        "  \n",
        "  question= clean_text(results[i][0])\n",
        "  answer = clean_text(results[i][1])\n",
        "\n",
        "#   print(question)\n",
        "#   print(answer)\n",
        "  seqq = [word_to_idx[wordQ] for wordQ in question.split() if wordQ in word_to_idx]\n",
        "  question= pad_sequences([seqq],maxlen=max_q,value=0,padding='post')[0]\n",
        "\n",
        "  seqa = [word_to_idx[wordA] for wordA in answer.split() if wordA in word_to_idx]\n",
        "  answer = pad_sequences([seqa],maxlen=max_a,value=0,padding='post')[0]\n",
        "  \n",
        "#   question = question.reshape((1,question.shape[0]))\n",
        "#   answer = answer.reshape((1,answer.shape[0]))\n",
        "  \n",
        "  distractor = predict_distractors(question,answer)\n",
        "  distractor = str(distractor)\n",
        "  distractor = distractor[1:-1]\n",
        "  results[i][2] = distractor\n",
        "  \n",
        "  if (i+1)%100==0:\n",
        "    print(\"questions done\",i+1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "questions done 9200\n",
            "questions done 9300\n",
            "questions done 9400\n",
            "questions done 9500\n",
            "questions done 9600\n",
            "questions done 9700\n",
            "questions done 9800\n",
            "questions done 9900\n",
            "questions done 10000\n",
            "questions done 10100\n",
            "questions done 10200\n",
            "questions done 10300\n",
            "questions done 10400\n",
            "questions done 10500\n",
            "questions done 10600\n",
            "questions done 10700\n",
            "questions done 10800\n",
            "questions done 10900\n",
            "questions done 11000\n",
            "questions done 11100\n",
            "questions done 11200\n",
            "questions done 11300\n",
            "questions done 11400\n",
            "questions done 11500\n",
            "questions done 11600\n",
            "questions done 11700\n",
            "questions done 11800\n",
            "questions done 11900\n",
            "questions done 12000\n",
            "questions done 12100\n",
            "questions done 12200\n",
            "questions done 12300\n",
            "questions done 12400\n",
            "questions done 12500\n",
            "questions done 12600\n",
            "questions done 12700\n",
            "questions done 12800\n",
            "questions done 12900\n",
            "questions done 13000\n",
            "questions done 13100\n",
            "questions done 13200\n",
            "questions done 13300\n",
            "questions done 13400\n",
            "questions done 13500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaxI7HoFb1N7",
        "colab_type": "text"
      },
      "source": [
        "### Conversion of Final Results to Results.csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQHCk_clXyA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = pd.DataFrame(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbzk2I_nXyPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.to_csv(\"./Results.csv\",header=[\"question\",\"answer_text\",\"distractor\"],index = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mg9Oa0rgzT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}